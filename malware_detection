#read files from codingfile_train.tsv and then store data into row_df
row_df = sqlContext.read.format("csv")\
.option("header", "true") \
.option("delimiter", "\t") \,
.load(Path+"codingfile_train.tsv")


from pyspark.sql.functions import col
import pyspark.sql.types
#split the data into two train data and test data
train_malware, test_malware=row_df.randomSplit([0.7, 0.3])

#randomforestclassifier model setting
from pyspark.ml.classification import RandomForestClassifier
rf =RandomForestClassifier(labelCol="label", featuresCol="features",numTrees=10)

#find the best model using the cross validation

from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml import Pipeline

paramGrid = ParamGridBuilder()\
.addGrid(rf.impurity, [ "gini","entropy"])\
.addGrid(rf.maxDepth, [ 5,10,15])\
.addGrid(rf.maxBins, [10, 15,20])\
.addGrid(rf.numTrees, [10, 20,30])\
.build()

rfcv = CrossValidator(estimator=rf, evaluator=evaluator,
                        estimatorParamMaps=paramGrid, numFolds=3)

rfcv_pipeline = Pipeline(stages=[rfcv])
rfcv_pipelineModel = rfcv_pipeline.fit(train_malware)
    
# identify malware coding data on test data   
rfcvpredictions = rfcv_pipelineModel.transform(test_malware) 
    
    
