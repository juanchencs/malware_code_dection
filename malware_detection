#read files
row_df = sqlContext.read.format("csv")\
.option("header", "true") \
.option("delimiter", "\t") \,
.load(Path+"codingfile_train.tsv")

#
from pyspark.sql.functions import col
import pyspark.sql.types

train_malware, test_malware=row_df.randomSplit([0.7, 0.3])

from pyspark.ml.classification import RandomForestClassifier
rf =RandomForestClassifier(labelCol="label", featuresCol="features",numTrees=10)
rfpipeline = Pipeline(stages=[stringIndexer,encoder ,assembler,rf ])

rfpipelineModel = rfpipeline.fit(train_malware)
rfpredicted=rfpipelineModel.transform(test_malware)
evaluator.evaluate(rfpredicted)

#find the best model using train validation
from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.classification import RandomForestClassifier

paramGrid = ParamGridBuilder()\
.addGrid(rf.impurity, [ \"gini\",\"entropy\"])\
.addGrid(rf.maxDepth, [ 5,10,15])\
.addGrid(rf.maxBins, [10, 15,20])\
.addGrid(rf.numTrees, [10, 20,30])\
.build()

rftvs = TrainValidationSplit(estimator=rf, evaluator=evaluator,
                                     estimatorParamMaps=paramGrid, trainRatio=0.8)
 
rftvs_pipeline = Pipeline(stages=[stringIndexer,encoder ,assembler, rftvs])
rftvs_pipelineModel =rftvs_pipeline.fit(train_malware)
rftvspredictions = rftvs_pipelineModel.transform(test_malware)
auc= evaluator.evaluate(rftvspredictions)


from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml import Pipeline

rfcv = CrossValidator(estimator=rf, evaluator=evaluator,
                        estimatorParamMaps=paramGrid, numFolds=3)

rfcv_pipeline = Pipeline(stages=[stringIndexer,encoder ,assembler, rfcv])
rfcv_pipelineModel = rfcv_pipeline.fit(train_malware)
    
# using model on test data set    
rfcvpredictions = rfcv_pipelineModel.transform(test_malware) 
    
    
